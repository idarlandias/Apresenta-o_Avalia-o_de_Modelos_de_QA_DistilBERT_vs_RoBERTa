# RESUMO PARA APRESENTA√á√ÉO DO TRABALHO
## Avalia√ß√£o de Modelos de Question Answering

---

## üéØ O QUE EU FIZ NESTE TRABALHO

Comparei dois modelos de Question Answering do Hugging Face usando 1.000 perguntas do dataset DBpedia:

- **Modelo 1**: DistilBERT (distilbert-base-cased-distilled-squad)
- **Modelo 2**: RoBERTa (deepset/roberta-base-squad2)

---

## üìä CRIT√âRIO A - TAMANHO M√âDIO DAS PERGUNTAS

**O que fiz**: Calculei quantas palavras tem cada pergunta em m√©dia.

**Resultado**: As perguntas t√™m em m√©dia **4.80 palavras**.

**Por que isso importa**: Perguntas curtas como "who is X" ou "what year" tendem a ter respostas mais diretas. Perguntas maiores costumam ser mais complexas.

---

## üìä CRIT√âRIO B - SCORE M√âDIO E QUALIDADE

**O que fiz**: Calculei a confian√ßa m√©dia de cada modelo e analisei se essa confian√ßa reflete a qualidade real.

**Resultados**:
- DistilBERT: score m√©dio de **0.4131**
- RoBERTa: score m√©dio de **0.3310**

**Minha an√°lise sobre score vs qualidade**:

O score √© parcialmente confi√°vel:
- **Scores muito altos (>0.95)** ‚Üí geralmente a resposta est√° correta e expl√≠cita no texto
- **Scores muito baixos (<0.02)** ‚Üí o modelo est√° incerto, e faz sentido porque a pergunta √© amb√≠gua ou n√£o tem resposta clara
- **Scores intermedi√°rios** ‚Üí n√£o d√° pra confiar cegamente, precisa verificar

**Exemplo que comprova isso**: A pergunta "who played tarzan in the movies" teve score 0.98, mas a resposta foi "Tarzan" (o personagem, n√£o o ator). Ou seja, score alto n√£o garante resposta certa.

---

## üìä CRIT√âRIO C - OVERLAP (SOBREPOSI√á√ÉO)

**O que fiz**: Medi quanto das palavras da resposta aparecem no texto original.

**Resultados**:
- DistilBERT: overlap m√©dio de **83.71%**
- RoBERTa: overlap m√©dio de **78.41%**

**O que isso significa**:

| Overlap | Interpreta√ß√£o |
|---------|---------------|
| Alto (>90%) | Resposta copiada direto do texto - baixo risco de erro |
| M√©dio (50-90%) | Resposta parcial - precisa verificar |
| Baixo (<50%) | Poss√≠vel alucina√ß√£o - o modelo pode ter inventado |

**Compara√ß√£o dos modelos**:
- DistilBERT teve **7.7%** de casos com overlap baixo (poss√≠vel alucina√ß√£o)
- RoBERTa teve **12.2%** de casos com overlap baixo

**Conclus√£o**: DistilBERT √© mais conservador e erra menos "inventando" coisas.

---

## üìä CRIT√âRIO D - AN√ÅLISE QUALITATIVA DOS 25 EXEMPLOS

**O que fiz**: Analisei manualmente 25 exemplos espec√≠ficos:
- 10 com maior score (onde o modelo tinha mais confian√ßa)
- 10 com menor score (onde o modelo tinha menos confian√ßa)
- 5 onde os modelos deram respostas diferentes

### MEUS ACHADOS NO TOP 10 (MAIOR SCORE):

Analisando os exemplos com score mais alto, percebi que:
- Perguntas do tipo "who is", "what year", "what nationality" funcionam muito bem
- Quando a resposta √© um nome, data ou fato √∫nico, o modelo acerta
- Exemplo: "who started labatt beer" ‚Üí "John Kinder Labatt" (correto!)
- Exemplo: "what year was the jacquard loom invented" ‚Üí "1801" (correto!)

**Minha conclus√£o**: O DistilBERT √© excelente para perguntas factuais simples.

### MEUS ACHADOS NO BOTTOM 10 (MENOR SCORE):

Analisando os exemplos com score mais baixo, percebi que:
- S√£o perguntas abertas ou sem resposta √∫nica
- Exemplo: "what books did tolkien write" - tem v√°rios livros, n√£o s√≥ um
- Exemplo: "kyrgyz population" - o texto n√£o tinha o n√∫mero exato

**Minha conclus√£o**: O modelo sabe quando n√£o sabe! O score baixo √© um aviso de "n√£o confie muito em mim aqui".

### MEUS ACHADOS NOS 5 DIVERGENTES:

Quando os modelos discordaram, analisei quem estava mais certo:

1. **"what is the jazz guitar"**
   - DistilBERT: deu a defini√ß√£o (correto)
   - RoBERTa: falou de amplifica√ß√£o (detalhe t√©cnico, n√£o a defini√ß√£o)
   - **Vencedor**: DistilBERT

2. **"what river is javari located in"**
   - DistilBERT: "The Javary River" (√© o pr√≥prio rio)
   - RoBERTa: "the Amazon" (√© a bacia, n√£o onde est√°)
   - **Vencedor**: DistilBERT

3. **"youngest female chess player"**
   - DistilBERT: resposta incompleta
   - RoBERTa: "Bobby Fischer" (que √© HOMEM!)
   - **Vencedor**: Nenhum, mas RoBERTa errou feio

4. **"who makes jupiter computer"**
   - DistilBERT: resposta confusa
   - RoBERTa: identificou que √© uma empresa
   - **Vencedor**: RoBERTa

5. **"what are jewish holidays"**
   - DistilBERT: resposta redundante
   - RoBERTa: mais direto
   - **Vencedor**: RoBERTa

**Placar final dos divergentes**: 2x2, com 1 empate. Mas os erros do RoBERTa foram mais graves (como errar o g√™nero da pessoa).

---

## üèÜ MINHA ESCOLHA PARA PRODU√á√ÉO: DISTILBERT

### Por que escolhi o DistilBERT?

Baseado na minha an√°lise dos 25 exemplos (n√£o s√≥ nas m√©tricas):

1. **No Top 10**: Acertou todas as perguntas factuais que analisei
2. **No Bottom 10**: Sinalizou corretamente quando n√£o tinha certeza
3. **Nos Divergentes**: Quando o RoBERTa errou, errou feio (ex: Bobby Fischer pra pergunta sobre mulher)
4. **Menos alucina√ß√µes**: 7.7% vs 12.2% de casos problem√°ticos

### Quando eu N√ÉO usaria o DistilBERT:

- Perguntas abertas tipo "o que √©..." ou "defina..."
- Quando preciso de respostas mais interpretativas
- Nesses casos, talvez um modelo maior ou generativo fosse melhor

---

## üí° O QUE EU APRENDI COM ESTE TRABALHO

1. **Score alto n√£o garante resposta certa** - vi exemplos de score 0.98 com resposta errada

2. **Overlap √© um bom indicador de confiabilidade** - se a resposta n√£o est√° no texto, desconfie

3. **Modelos menores podem ser melhores** - o DistilBERT √© menor e mais r√°pido, mas foi mais confi√°vel que o RoBERTa no meu dataset

4. **An√°lise qualitativa √© essencial** - s√≥ olhando os n√∫meros eu n√£o teria percebido o erro grave do Bobby Fischer

5. **Em produ√ß√£o, precisa de filtros** - n√£o d√° pra confiar cegamente no modelo, precisa de thresholds e revis√£o humana

---

## üìà RESUMO DOS N√öMEROS

| M√©trica | DistilBERT | RoBERTa |
|---------|------------|---------|
| Score M√©dio | 0.4131 | 0.3310 |
| Overlap M√©dio | 83.71% | 78.41% |
| Casos com overlap ‚â•90% | 62.6% | 53.3% |
| Casos com overlap <50% (risco) | 7.7% | 12.2% |
| Tamanho m√©dio das perguntas | 4.80 palavras | 4.80 palavras |

---

## ‚úÖ CHECKLIST DO QUE ENTREGUEI

- [x] 1.000 exemplos do shard_007
- [x] Dois modelos diferentes do Hugging Face
- [x] Tamanho m√©dio das perguntas calculado
- [x] Score m√©dio calculado e analisado
- [x] Overlap calculado e interpretado
- [x] 10 exemplos Top analisados manualmente
- [x] 10 exemplos Bottom analisados manualmente
- [x] 5 exemplos Divergentes analisados manualmente
- [x] An√°lise de contexto, corre√ß√£o e alucina√ß√£o
- [x] Escolha de modelo para produ√ß√£o fundamentada na an√°lise qualitativa
